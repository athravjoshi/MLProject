{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUs3GMNLSDhB/niQsaRcvP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athravjoshi/MLProject/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***GENAI using gemeni***"
      ],
      "metadata": {
        "id": "9jyrhd3GN2g1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VuJuVRXV0wgu"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "import textwrap\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('.',' *')\n",
        "    return Markdown(textwrap.indent(text,'>',predicate=lambda _:True))"
      ],
      "metadata": {
        "id": "08kihUpIOlWG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "789TWXYhPX9L"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TEXT Generation***\n"
      ],
      "metadata": {
        "id": "DxovLmvPQcVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-2.5-pro\")\n",
        "model\n",
        "\n",
        "# model = genai.list_models()\n",
        "# model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijkw3ud8QUgm",
        "outputId": "523263c1-850c-48ee-fbe6-8ddb818713cc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-2.5-pro',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=None,\n",
              "    cached_content=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import google.generativeai as genai\n",
        "\n",
        "# genai.configure(api_key=\"AIzaSyCP_yK4Ir_FznOZPTaQClXkaMdUjJKeiq8\")\n"
      ],
      "metadata": {
        "id": "a1uqv3vC8CIT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# response = model.generate_content(\"what are the usecaase of llm\")\n",
        "\n",
        "\n",
        "# model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
        "response = model.generate_content(\"what are the use cases of LLM?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-DRwsBoqRdDn",
        "outputId": "81d10adf-38ca-4c7f-8645-f46a7cce5deb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course. Large Language Models (LLMs) have a vast and rapidly growing range of use cases because their core ability is to understand, process, and generate human-like text. They are essentially powerful pattern-recognition engines for language.\n",
            "\n",
            "We can break down their use cases into categories based on their core capabilities.\n",
            "\n",
            "### Core Capabilities Driving the Use Cases\n",
            "\n",
            "First, let's understand the fundamental tasks LLMs are good at. Almost every use case is a variation or combination of these:\n",
            "\n",
            "1.  **Text Generation:** Creating new text from a prompt (e.g., writing an essay, an email, or a poem).\n",
            "2.  **Summarization:** Condensing long documents into key points.\n",
            "3.  **Translation:** Translating text from one language to another.\n",
            "4.  **Classification & Categorization:** Assigning labels to text (e.g., sentiment analysis, topic categorization).\n",
            "5.  **Information Extraction:** Pulling specific, structured data from unstructured text (e.g., extracting names and dates from a contract).\n",
            "6.  **Question Answering & Conversational AI:** Answering questions based on a given context or its general knowledge, and engaging in dialogue.\n",
            "7.  **Rewriting & Paraphrasing:** Rephrasing text to change its tone, simplify it, or fix grammar.\n",
            "8.  **Code Generation & Understanding:** Writing, explaining, debugging, and translating computer code.\n",
            "\n",
            "---\n",
            "\n",
            "### Key Use Cases by Domain\n",
            "\n",
            "Here are the most common and impactful use cases, organized by area:\n",
            "\n",
            "#### 1. Content Creation & Marketing\n",
            "This is one of the most popular applications for LLMs.\n",
            "\n",
            "*   **Copywriting:** Generating persuasive ad copy, product descriptions, and website headlines.\n",
            "*   **Content Generation:** Drafting entire blog posts, articles, and white papers.\n",
            "*   **Email Marketing:** Writing personalized email campaigns, subject lines, and follow-ups.\n",
            "*   **Social Media Management:** Creating captions for posts, brainstorming content ideas, and generating entire content calendars.\n",
            "*   **SEO (Search Engine Optimization):** Generating keyword-rich content, meta descriptions, and finding related topic ideas.\n",
            "*   **Scriptwriting:** Drafting scripts for videos, podcasts, and presentations.\n",
            "\n",
            "#### 2. Business Operations & Analytics\n",
            "LLMs are transforming internal business processes by automating tedious tasks.\n",
            "\n",
            "*   **Meeting Summarization:** Transcribing audio from meetings and generating concise summaries with action items.\n",
            "*   **Report Generation:** Analyzing raw data (like sales figures or survey results) and generating human-readable reports and insights.\n",
            "*   **Internal Knowledge Base:** Creating a \"chat with your documents\" system where employees can ask questions about company policies, technical documentation, or project histories.\n",
            "*   **Market Research:** Analyzing customer reviews, social media trends, and news articles to identify market sentiment and competitive intelligence.\n",
            "*   **Legal & Compliance:** Summarizing complex legal contracts, identifying clauses, and ensuring documents adhere to templates.\n",
            "\n",
            "#### 3. Customer Support & Engagement\n",
            "LLMs are powering the next generation of customer service.\n",
            "\n",
            "*   **Intelligent Chatbots & Virtual Assistants:** Providing 24/7 customer support, answering FAQs, and guiding users through processes. Unlike old chatbots, they can understand context and nuance.\n",
            "*   **Agent Assist:** Providing human support agents with real-time suggestions, draft replies, and access to relevant knowledge base articles during a call or chat.\n",
            "*   **Sentiment Analysis:** Analyzing customer emails, chat logs, and reviews to gauge satisfaction and identify urgent issues.\n",
            "*   **Automated Ticket Categorization:** Automatically routing customer support tickets to the right department based on the content of the query.\n",
            "\n",
            "#### 4. Software Development & IT\n",
            "This is a massive area of growth, significantly boosting developer productivity.\n",
            "\n",
            "*   **Code Generation:** Writing boilerplate code, functions, or even entire algorithms based on a natural language description (e.g., \"Write a Python function to sort a list of dictionaries by a specific key\").\n",
            "*   **Code Explanation:** Explaining what a complex piece of code does in plain English, which is invaluable for learning and collaboration.\n",
            "*   **Debugging:** Suggesting fixes for buggy code and explaining the source of the error.\n",
            "*   **Code Translation:** Converting code from one programming language to another (e.g., Python to JavaScript).\n",
            "*   **Writing Documentation:** Automatically generating documentation and comments for code.\n",
            "\n",
            "#### 5. Education & Research\n",
            "LLMs are becoming powerful tools for learning and discovery.\n",
            "\n",
            "*   **Personalized Tutoring:** Acting as an \"always-on\" tutor that can explain complex concepts in simple terms, tailored to a student's level of understanding.\n",
            "*   **Research Assistant:** Summarizing academic papers, finding relevant literature, and helping to structure a research thesis or paper.\n",
            "*   **Language Learning:** Providing a conversation partner for practicing a new language, explaining grammar rules, and correcting mistakes.\n",
            "*   **Generating Learning Materials:** Creating quizzes, practice problems, and study guides on any topic.\n",
            "\n",
            "#### 6. Creative & Entertainment\n",
            "LLMs are powerful creative partners.\n",
            "\n",
            "*   **Brainstorming:** Acting as a brainstorming partner for novelists, screenwriters, and artists to generate ideas, plot twists, or character concepts.\n",
            "*   **Co-writing:** Assisting in writing poetry, song lyrics, and short stories.\n",
            "*   **Game Development:** Generating dialogue for non-player characters (NPCs), creating item descriptions, and writing quest narratives.\n",
            "*   **Role-playing:** Acting as a Dungeon Master for tabletop role-playing games like D&D.\n",
            "\n",
            "#### 7. Personal Productivity\n",
            "Individuals use LLMs as personal assistants to manage daily life.\n",
            "\n",
            "*   **Drafting Communications:** Quickly writing professional emails, thank-you notes, or difficult conversations.\n",
            "*   **Planning & Organization:** Creating travel itineraries, meal plans, workout routines, and project outlines.\n",
            "*   **Learning New Skills:** Getting step-by-step instructions for anything from fixing a leaky faucet to learning a new software tool.\n",
            "*   **Summarizing Content:** Condensing long articles, videos (via transcript), or books to quickly grasp the main ideas.\n",
            "\n",
            "In short, if a task involves language, data, or code, there's a good chance an LLM can be used to automate, augment, or accelerate it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in genai.list_models():\n",
        "    print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kzwQSgwGSxHH",
        "outputId": "55f52f82-40a7-4544-d07d-4e07d45c1815"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/imagen-4.0-generate-001\n",
            "models/imagen-4.0-ultra-generate-001\n",
            "models/imagen-4.0-fast-generate-001\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-preview\n",
            "models/veo-3.0-fast-generate-preview\n",
            "models/veo-3.0-generate-001\n",
            "models/veo-3.0-fast-generate-001\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n",
            "models/gemini-2.5-flash-live-preview\n",
            "models/gemini-2.5-flash-native-audio-latest\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "beH9ecMXRczK"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}